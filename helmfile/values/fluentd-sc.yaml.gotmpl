fullnameOverride: fluentd

resources: {{- toYaml .Values.fluentd.resources | nindent 2  }}
nodeSelector: {{- toYaml .Values.fluentd.nodeSelector | nindent 2  }}
affinity: {{- toYaml .Values.fluentd.affinity | nindent 2  }}
tolerations: {{- toYaml .Values.fluentd.tolerations | nindent 2  }}

# Default args include "-q" which sets loglevel to warning.
fluentdArgs: "--no-supervisor -q"
configMaps:
  useDefaults:
    systemConf: false
    containersInputConf: false
    outputConf: false

additionalPlugins:
  #New version due to https://github.com/fluent/fluent-plugin-prometheus/issues/119
  #default: gem 'fluent-plugin-prometheus', '~>1.4.0'
- name: fluent-plugin-prometheus
  version: 1.6.1

env:
  LIVENESS_THRESHOLD_SECONDS: 900
  STUCK_THRESHOLD_SECONDS: 1200

serviceMonitor:
  enabled: true
  interval: 20s
  port: 24231

extraConfigMaps:
  system.conf: |-
    <system>
      root_dir /tmp/fluentd-buffers/
      <log>
        format json
      </log>
    </system>
  10-kube-audit.conf: |-
    <source>
      @id kube-audit
      @type tail
      path /var/log/kube-audit/kube-apiserver.log
      pos_file /var/log/kube-audit/fluentd-kube-apiserver.pos
      tag kubeaudit.*
      read_from_head true
      <parse>
        @type multi_format
        <pattern>
          format json
          time_key time
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </pattern>
      </parse>
    </source>
    # Remove keys that include raw data causing errors
    # See: https://github.com/uken/fluent-plugin-elasticsearch/issues/452
    <filter kubeaudit.**>
      @id kube_api_audit_normalize
      @type record_transformer
      remove_keys responseObject,requestObject
    </filter>

  containers.input.conf: |-
    #This config is taken from a default config that we have disabled
    #See the value "configMaps.useDefaults.containersInputConf: false" above
    #But we added "reserve_time true" in order to allow falco logs to use json
    <source>
      @id fluentd-containers.log
      @type tail
      path /var/log/containers/*.log
      pos_file /var/log/containers.log.pos
      tag raw.kubernetes.*
      read_from_head true
      <parse>
        @type multi_format
        <pattern>
          format json
          time_key time
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </pattern>
        <pattern>
          format /^(?<time>.+) (?<stream>stdout|stderr) [^ ]* (?<log>.*)$/
          time_format %Y-%m-%dT%H:%M:%S.%N%:z
        </pattern>
      </parse>
    </source>

    # Detect exceptions in the log output and forward them as one log entry.
    <match raw.kubernetes.**>
      @id raw.kubernetes
      @type detect_exceptions
      remove_tag_prefix raw
      message log
      stream stream
      multiline_flush_interval 5
      max_bytes 500000
      max_lines 1000
    </match>

    # Concatenate multi-line logs
    <filter **>
      @id filter_concat
      @type concat
      key message
      multiline_end_regexp /\n$/
      separator ""
    </filter>

    # Enriches records with Kubernetes metadata
    <filter kubernetes.**>
      @id filter_kubernetes_metadata
      @type kubernetes_metadata
    </filter>

    # Fixes json fields in Elasticsearch
    <filter kubernetes.**>
      @id filter_parser
      @type parser
      key_name log
      reserve_data true
      reserve_time true #This is the line that is changed from the default config
      remove_key_name_field true
      <parse>
        @type multi_format
        <pattern>
          format json
        </pattern>
        <pattern>
          format none
        </pattern>
      </parse>
    </filter>

    # count number of incoming records per tag
    <filter **>
      @type prometheus
      <metric>
        name fluentd_input_status_num_records_total
        type counter
        desc The total number of incoming records
        <labels>
          tag ${tag}
          hostname ${hostname}
        </labels>
      </metric>
    </filter>

  output.conf: |-
    <match **>
      @id output-forwarding
      @type forward
      send_timeout 60s
      recover_wait 10s
      hard_timeout 60s
      <server>
        name aggregator
        host fluentd-aggregator
        port 24224
        weight 60
      </server>
      #<secondary>
      #  @type file
      #  path /var/log/fluentd/forward-failed
      #</secondary>
      <buffer>
        @type file
        path /var/log/fluentd-buffers
        flush_mode interval
        retry_type exponential_backoff
        flush_thread_count 2
        flush_interval 5s
        retry_forever
        retry_max_interval 30
        chunk_limit_size "#{ENV['OUTPUT_BUFFER_CHUNK_LIMIT']}"
        queue_limit_length "#{ENV['OUTPUT_BUFFER_QUEUE_LIMIT']}"
        overflow_action block
      </buffer>
    </match>
    <match **>
      @type prometheus
      <metric>
        name fluentd_output_status_num_records_total
        type counter
        desc The total number of outgoing records
        <labels>
          tag ${tag}
          hostname ${hostname}
        </labels>
      </metric>
    </match>
