# Image vulnerability scanning

As part of an investigation task I tested to add [starboard](https://aquasecurity.github.io/starboard/v0.10.1/) to run image scanning in a running cluster, then expose the results as prometheus metrics and show them in a grafana dashboard.

## What was done

### Install Starboard

I installed the Starboard operator via helm, see this guide: https://aquasecurity.github.io/starboard/v0.10.1/operator/installation/helm/

In order to scan all namespaces I set `targetNamespaces=""`.

### Scan images

With the starboard operator installed all images should be automatically scanned and generate `vulnerabilityreports` objects in kubernetes. There you can see all vulnerabilities for a specific replicaSet/daemonSet/pod.

### Export metrics

I created a deployment that mimiced the setup we run in influxdb (see here: https://github.com/elastisys/compliantkubernetes-apps/blob/3e31577a0d9bddb4ecdb4dea59b2ff8dd57a0a24/helmfile/values/influxdb.yaml.gotmpl#L127) with one container that adds metrics to a file and a node-exporter container that reads that file.

The container that adds metrics follows this rough script:
```bash
# Set variables to enable requests to api-server
APISERVER=https://kubernetes.default.svc
SERVICEACCOUNT=/var/run/secrets/kubernetes.io/serviceaccount
NAMESPACE=$(cat ${SERVICEACCOUNT}/namespace)
TOKEN=$(cat ${SERVICEACCOUNT}/token)
CACERT=${SERVICEACCOUNT}/ca.crt


while true; do

# Get data from api-server
curl --cacert ${CACERT} --header "Authorization: Bearer ${TOKEN}" -X GET ${APISERVER}/apis/aquasecurity.github.io/v1alpha1/vulnerabilityreports > /textfile-collector/tmp-reports.json

# Parse metrics for vulnerabilities with low severity
# In the end we want something like this:
# image_vulnerability{name="pod-nginx-nginx",namespace="default",severity="low"} 0

cat /textfile-collector/tmp-reports.json \
    | jq '.items[] | {name: .metadata.name, namespace: .metadata.namespace, severity: "low", result: .report.summary.lowCount}' -c | \ #Parse json data
    sed 's/,"result":\([0-9]\+\)}/} \1/' | \ # move result to after "}"
    sed 's/^/image_vulnerability/' | \ # add metric name
    sed 's/"\([a-z]\+\)":/\1=/g' \ # convert '"key": ' to 'key='
    > /textfile-collector/tmp-metrics # write to tmp-file
# Parse metrics for vulnerabilities with medium severity
cat /textfile-collector/tmp-reports.json | jq '.items[] | {name: .metadata.name, namespace: .metadata.namespace, severity: "medium", result: .report.summary.mediumCount}' -c | sed 's/,"result":\([0-9]\+\)}/} \1/' | sed 's/^/image_vulnerability/' | sed 's/"\([a-z]\+\)":/\1=/g' >> /textfile-collector/tmp-metrics
# Parse metrics for vulnerabilities with high severity
cat /textfile-collector/tmp-reports.json | jq '.items[] | {name: .metadata.name, namespace: .metadata.namespace, severity: "high", result: .report.summary.highCount}' -c | sed 's/,"result":\([0-9]\+\)}/} \1/' | sed 's/^/image_vulnerability/' | sed 's/"\([a-z]\+\)":/\1=/g' >> /textfile-collector/tmp-metrics
# Parse metrics for vulnerabilities with critical severity
cat /textfile-collector/tmp-reports.json | jq '.items[] | {name: .metadata.name, namespace: .metadata.namespace, severity: "critical", result: .report.summary.criticalCount}' -c | sed 's/,"result":\([0-9]\+\)}/} \1/' | sed 's/^/image_vulnerability/' | sed 's/"\([a-z]\+\)":/\1=/g' >> /textfile-collector/tmp-metrics
# Parse metrics for vulnerabilities with unknown severity
cat /textfile-collector/tmp-reports.json | jq '.items[] | {name: .metadata.name, namespace: .metadata.namespace, severity: "unknown", result: .report.summary.unknownCount}' -c | sed 's/,"result":\([0-9]\+\)}/} \1/' | sed 's/^/image_vulnerability/' | sed 's/"\([a-z]\+\)":/\1=/g' >> /textfile-collector/tmp-metrics

# Write metrics to the file that node-exporter uses
cat /textfile-collector/tmp-metrics > /textfile-collector/vulnerabilities.prom
# Sleep, this should be improved
sleep 10
done
```

### Dashboard

A simple dashboard exists to show the number of vulnerabilities with some filtering. See `vulnerability-dashboard.json`

## TODO

Some improvements we could/should do.

### Starboard installation

- We should add this helm chart to our helmfile
- We should look through the values. We could at least disable some of the other components that we do not use (e.g. kube-bench).
- Check if some values should be exposed as config.

### Exporting metrics.

- everything is nameed "curl-jq" replace that with an appropriate name
- node-exporter seems to require root privileges, check if this can be changed or if we can use some other exporter.
- The parsing is rather "hacky", maybe this could be simplified/improved.
- Re-think how often we should write the metrics to file, I just put a sleep of 10 seconds in order to not do it too often.
- Check if there are more lables we could want. Examples: image name, image tag, type of kubernetes object (pod, replicaSet, ...)

### Dashboard

- Add dashboard to our dashboard chart
- Add some text linking explaining that you can check the whole vulnerability reports in the kubernetes api
- Depending on which labels we might want to add, we should also update the dashboard to use them

### Public docs

- Add some text on how what the dashboard is used for and how to view the full vulnerability reports in the kubernetes api
